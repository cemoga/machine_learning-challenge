{
 "cells": [
  {
   "source": [
    "import numpy as np \n",
    "X = np.load('X.npy', allow_pickle=False)\n",
    "X = np.array(X)\n",
    "y_text = np.load('y.npy', allow_pickle=False)\n",
    "y_text = np.array(y_text)\n",
    "\n",
    "\n",
    "print(\"X Shape:\", X.shape)\n",
    "print(\"y Shape:\", y_text.shape)\n",
    "print(\"y_text:\", y_text[1000])\n",
    "X.shape[1:]"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X Shape: (15579, 50, 50)\ny Shape: (15579,)\ny_text: restaurant\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(50, 50)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {},
   "execution_count": 24
  },
  {
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# Encode the 67 categories into binary numbers\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y_text)\n",
    "print(\"y:\", y[1000])\n",
    "# Sample to decode the binary encoding\n",
    "inverse = encoder.inverse_transform(y)\n",
    "print(inverse[1000])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "y: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\nrestaurant\n"
    }
   ],
   "metadata": {},
   "execution_count": 25
  },
  {
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 26
  },
  {
   "source": [
    "print(y_train[0])\n",
    "print(y_train[1])\n",
    "print(\"X_train Shape:\", X_train.shape)\n",
    "print(\"y_train Shape:\", y_train.shape)\n",
    "print(\"X_test Shape:\", X_test.shape)\n",
    "print(\"y_test Shape:\", y_test.shape)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nX_train Shape: (11684, 50, 50)\ny_train Shape: (11684, 67)\nX_test Shape: (3895, 50, 50)\ny_test Shape: (3895, 67)\n"
    }
   ],
   "metadata": {},
   "execution_count": 27
  },
  {
   "source": [
    "X_train"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[ 15,  13,   9, ...,  78,  81,  61],\n        [ 31,  21,  21, ...,  75,  69,  58],\n        [ 70,  41,  42, ...,  96,  61,  59],\n        ...,\n        [ 37,  52,  55, ..., 143, 135, 154],\n        [ 29,  35,  58, ..., 188, 147, 159],\n        [ 29,  32,  36, ..., 208, 155, 185]],\n\n       [[119, 122, 125, ..., 107, 102, 105],\n        [115, 115, 123, ...,  54,  57,  86],\n        [116, 117, 123, ...,  77,  75,  69],\n        ...,\n        [  6,  13,  35, ..., 145, 137, 141],\n        [  6,  28,  43, ..., 144, 133, 138],\n        [ 18,  42,  56, ..., 134, 123, 124]],\n\n       [[254, 255, 197, ..., 145, 145, 143],\n        [198, 249, 255, ..., 144, 143, 141],\n        [253, 250, 255, ..., 144, 142, 142],\n        ...,\n        [ 78,  76,  78, ...,  78,  70,  72],\n        [ 87,  80,  81, ...,  83,  69,  69],\n        [ 82,  76,  87, ...,  87,  67,  40]],\n\n       ...,\n\n       [[ 74,  76,  75, ...,  19,  23,  78],\n        [ 48,  79,  79, ...,  85,  78,  72],\n        [ 74,  80,  84, ...,  86,  76,  78],\n        ...,\n        [ 23,  24,  31, ...,   5,   7,   8],\n        [ 23,  22,  29, ...,   8,   7,   8],\n        [ 25,  22,  29, ...,   9,   9,  13]],\n\n       [[ 40,  31,  34, ...,  17,   0,  14],\n        [ 98, 136, 138, ...,  23,   8,  13],\n        [118, 120, 124, ...,  30,  18,   3],\n        ...,\n        [130,  91, 109, ...,   5, 163, 161],\n        [104, 110, 103, ...,  72,  66,  78],\n        [118,  25,   1, ...,  78, 111,  87]],\n\n       [[ 40,  38,  39, ...,  34,  37,  32],\n        [ 41,  24,  36, ...,  72,  75, 112],\n        [244, 132, 117, ...,  71,  71,  70],\n        ...,\n        [111, 106,  75, ...,  80,  94, 167],\n        [ 95,  71,  85, ...,  95, 116, 145],\n        [ 89,  65,  57, ...,  87, 159, 139]]], dtype=uint8)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {},
   "execution_count": 28
  },
  {
   "source": [
    "X_train = X_train.reshape(11684,50,50,1)\n",
    "X_test = X_test.reshape(3895,50,50,1)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 29
  },
  {
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "model = Sequential()"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 30
  },
  {
   "source": [
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(50,50,1)))"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 31
  },
  {
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 32
  },
  {
   "source": [
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 33
  },
  {
   "source": [
    "model.add(Flatten())"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 34
  },
  {
   "source": [
    "model.add(Dense(1000, activation='relu'))"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 35
  },
  {
   "source": [
    "model.add(Dense(67, activation='softmax'))"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 36
  },
  {
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 37
  },
  {
   "source": [
    "# We can summarize our model\n",
    "model.summary()"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 46, 46, 32)        832       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 23, 23, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 19, 19, 64)        51264     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 9, 9, 64)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 5184)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1000)              5185000   \n_________________________________________________________________\ndense_4 (Dense)              (None, 67)                67067     \n=================================================================\nTotal params: 5,304,163\nTrainable params: 5,304,163\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "metadata": {},
   "execution_count": 38
  },
  {
   "source": [
    "hist = model.fit(X_train, y_train, \n",
    "           batch_size=256, epochs=1000, validation_split=0.01)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ss: 0.0030 - accuracy: 0.9982 - val_loss: 27.8872 - val_accuracy: 0.0684\nEpoch 524/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0029 - accuracy: 0.9981 - val_loss: 27.6353 - val_accuracy: 0.0684\nEpoch 525/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0026 - accuracy: 0.9980 - val_loss: 27.4191 - val_accuracy: 0.0684\nEpoch 526/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 27.6080 - val_accuracy: 0.0684\nEpoch 527/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9981 - val_loss: 27.7219 - val_accuracy: 0.0855\nEpoch 528/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 27.4888 - val_accuracy: 0.0684\nEpoch 529/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9980 - val_loss: 27.2917 - val_accuracy: 0.0684\nEpoch 530/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9980 - val_loss: 27.3643 - val_accuracy: 0.0684\nEpoch 531/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 27.5777 - val_accuracy: 0.0684\nEpoch 532/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9981 - val_loss: 27.8790 - val_accuracy: 0.0769\nEpoch 533/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0025 - accuracy: 0.9981 - val_loss: 27.4603 - val_accuracy: 0.0684\nEpoch 534/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 27.6714 - val_accuracy: 0.0769\nEpoch 535/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0023 - accuracy: 0.9979 - val_loss: 27.8135 - val_accuracy: 0.0684\nEpoch 536/1000\n11567/11567 [==============================] - 41s 4ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 27.5080 - val_accuracy: 0.0684\nEpoch 537/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 27.4620 - val_accuracy: 0.0769\nEpoch 538/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 27.5980 - val_accuracy: 0.0684\nEpoch 539/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 27.4985 - val_accuracy: 0.0684\nEpoch 540/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0023 - accuracy: 0.9980 - val_loss: 27.6427 - val_accuracy: 0.0769\nEpoch 541/1000\n11567/11567 [==============================] - 48s 4ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 27.7957 - val_accuracy: 0.0855\nEpoch 542/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 27.4180 - val_accuracy: 0.0684\nEpoch 543/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0023 - accuracy: 0.9983 - val_loss: 27.4559 - val_accuracy: 0.0684\nEpoch 544/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9980 - val_loss: 27.4342 - val_accuracy: 0.0684\nEpoch 545/1000\n11567/11567 [==============================] - 44s 4ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 27.6504 - val_accuracy: 0.0684\nEpoch 546/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0023 - accuracy: 0.9981 - val_loss: 27.6021 - val_accuracy: 0.0684\nEpoch 547/1000\n11567/11567 [==============================] - 40s 3ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 27.6020 - val_accuracy: 0.0684\nEpoch 548/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 27.7276 - val_accuracy: 0.0769\nEpoch 549/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9980 - val_loss: 27.7575 - val_accuracy: 0.0684\nEpoch 550/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9981 - val_loss: 27.6571 - val_accuracy: 0.0684\nEpoch 551/1000\n11567/11567 [==============================] - 46s 4ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 27.8903 - val_accuracy: 0.0684\nEpoch 552/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 27.7874 - val_accuracy: 0.0684\nEpoch 553/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 27.6033 - val_accuracy: 0.0684\nEpoch 554/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 27.8762 - val_accuracy: 0.0684\nEpoch 555/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 27.6227 - val_accuracy: 0.0684\nEpoch 556/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 27.8001 - val_accuracy: 0.0684\nEpoch 557/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9978 - val_loss: 27.9827 - val_accuracy: 0.0769\nEpoch 558/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 28.0047 - val_accuracy: 0.0769\nEpoch 559/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 27.7494 - val_accuracy: 0.0684\nEpoch 560/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 27.7034 - val_accuracy: 0.0684\nEpoch 561/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0022 - accuracy: 0.9979 - val_loss: 27.9156 - val_accuracy: 0.0684\nEpoch 562/1000\n11567/11567 [==============================] - 49s 4ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 27.5502 - val_accuracy: 0.0684\nEpoch 563/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 27.8858 - val_accuracy: 0.0769\nEpoch 564/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0021 - accuracy: 0.9982 - val_loss: 27.7166 - val_accuracy: 0.0684\nEpoch 565/1000\n11567/11567 [==============================] - 41s 4ms/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 27.9033 - val_accuracy: 0.0684\nEpoch 566/1000\n11567/11567 [==============================] - 40s 3ms/step - loss: 0.0022 - accuracy: 0.9978 - val_loss: 27.6643 - val_accuracy: 0.0684\nEpoch 567/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 27.8508 - val_accuracy: 0.0684\nEpoch 568/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 27.3873 - val_accuracy: 0.0684\nEpoch 569/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 27.4059 - val_accuracy: 0.0684\nEpoch 570/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9985 - val_loss: 27.3229 - val_accuracy: 0.0769\nEpoch 571/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 27.3140 - val_accuracy: 0.0769\nEpoch 572/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 27.3342 - val_accuracy: 0.0598\nEpoch 573/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9979 - val_loss: 27.8580 - val_accuracy: 0.0598\nEpoch 574/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 28.7269 - val_accuracy: 0.0684\nEpoch 575/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 26.7041 - val_accuracy: 0.0855\nEpoch 576/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.1464 - accuracy: 0.9686 - val_loss: 29.3550 - val_accuracy: 0.0598\nEpoch 577/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.7357 - accuracy: 0.8859 - val_loss: 24.0876 - val_accuracy: 0.0513\nEpoch 578/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.4362 - accuracy: 0.9231 - val_loss: 26.4818 - val_accuracy: 0.0684\nEpoch 579/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.1219 - accuracy: 0.9741 - val_loss: 25.4803 - val_accuracy: 0.0598\nEpoch 580/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0511 - accuracy: 0.9882 - val_loss: 25.4535 - val_accuracy: 0.0769\nEpoch 581/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 25.1048 - val_accuracy: 0.0513\nEpoch 582/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 26.7180 - val_accuracy: 0.0598\nEpoch 583/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 26.6673 - val_accuracy: 0.0769\nEpoch 584/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 25.7983 - val_accuracy: 0.0684\nEpoch 585/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 25.6825 - val_accuracy: 0.0684\nEpoch 586/1000\n11567/11567 [==============================] - 40s 3ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 25.5837 - val_accuracy: 0.0598\nEpoch 587/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 25.9676 - val_accuracy: 0.0684\nEpoch 588/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 25.9215 - val_accuracy: 0.0684\nEpoch 589/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0031 - accuracy: 0.9980 - val_loss: 26.0830 - val_accuracy: 0.0684\nEpoch 590/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0035 - accuracy: 0.9979 - val_loss: 26.0363 - val_accuracy: 0.0684\nEpoch 591/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 26.0765 - val_accuracy: 0.0684\nEpoch 592/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 26.0315 - val_accuracy: 0.0684\nEpoch 593/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0029 - accuracy: 0.9978 - val_loss: 25.9390 - val_accuracy: 0.0684\nEpoch 594/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0027 - accuracy: 0.9983 - val_loss: 26.1147 - val_accuracy: 0.0684\nEpoch 595/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 26.0893 - val_accuracy: 0.0769\nEpoch 596/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 26.1984 - val_accuracy: 0.0684\nEpoch 597/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 26.2717 - val_accuracy: 0.0684\nEpoch 598/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 26.3417 - val_accuracy: 0.0684\nEpoch 599/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 26.2959 - val_accuracy: 0.0684\nEpoch 600/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 26.2061 - val_accuracy: 0.0684\nEpoch 601/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 26.2584 - val_accuracy: 0.0684\nEpoch 602/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0027 - accuracy: 0.9980 - val_loss: 26.1454 - val_accuracy: 0.0684\nEpoch 603/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 26.1721 - val_accuracy: 0.0684\nEpoch 604/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0026 - accuracy: 0.9981 - val_loss: 26.0917 - val_accuracy: 0.0684\nEpoch 605/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 26.0405 - val_accuracy: 0.0684\nEpoch 606/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 26.1730 - val_accuracy: 0.0684\nEpoch 607/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 26.2695 - val_accuracy: 0.0684\nEpoch 608/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 26.3564 - val_accuracy: 0.0684\nEpoch 609/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 26.2820 - val_accuracy: 0.0684\nEpoch 610/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0026 - accuracy: 0.9981 - val_loss: 26.3845 - val_accuracy: 0.0684\nEpoch 611/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 26.2326 - val_accuracy: 0.0684\nEpoch 612/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 26.2353 - val_accuracy: 0.0769\nEpoch 613/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 26.2237 - val_accuracy: 0.0684\nEpoch 614/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9981 - val_loss: 26.3780 - val_accuracy: 0.0684\nEpoch 615/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 26.1457 - val_accuracy: 0.0684\nEpoch 616/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 26.1794 - val_accuracy: 0.0769\nEpoch 617/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9980 - val_loss: 26.1889 - val_accuracy: 0.0769\nEpoch 618/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 26.4743 - val_accuracy: 0.0769\nEpoch 619/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 26.2422 - val_accuracy: 0.0769\nEpoch 620/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 26.1024 - val_accuracy: 0.0769\nEpoch 621/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9981 - val_loss: 26.1169 - val_accuracy: 0.0769\nEpoch 622/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 25.9785 - val_accuracy: 0.0769\nEpoch 623/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 26.0606 - val_accuracy: 0.0684\nEpoch 624/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9980 - val_loss: 25.9994 - val_accuracy: 0.0684\nEpoch 625/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9980 - val_loss: 25.9208 - val_accuracy: 0.0684\nEpoch 626/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 26.0077 - val_accuracy: 0.0684\nEpoch 627/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 26.3164 - val_accuracy: 0.0769\nEpoch 628/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 26.1565 - val_accuracy: 0.0769\nEpoch 629/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 26.2820 - val_accuracy: 0.0769\nEpoch 630/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 26.4082 - val_accuracy: 0.0769\nEpoch 631/1000\n11567/11567 [==============================] - 40s 3ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 26.4180 - val_accuracy: 0.0769\nEpoch 632/1000\n11567/11567 [==============================] - 43s 4ms/step - loss: 0.0023 - accuracy: 0.9981 - val_loss: 26.4110 - val_accuracy: 0.0769\nEpoch 633/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 26.4330 - val_accuracy: 0.0769\nEpoch 634/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 26.5268 - val_accuracy: 0.0769\nEpoch 635/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 26.2759 - val_accuracy: 0.0769\nEpoch 636/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0022 - accuracy: 0.9977 - val_loss: 26.2569 - val_accuracy: 0.0769\nEpoch 637/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 26.2862 - val_accuracy: 0.0769\nEpoch 638/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 26.3915 - val_accuracy: 0.0769\nEpoch 639/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0022 - accuracy: 0.9980 - val_loss: 26.3613 - val_accuracy: 0.0769\nEpoch 640/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 26.2667 - val_accuracy: 0.0769\nEpoch 641/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 26.2967 - val_accuracy: 0.0769\nEpoch 642/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0021 - accuracy: 0.9980 - val_loss: 26.4559 - val_accuracy: 0.0769\nEpoch 643/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 26.5855 - val_accuracy: 0.0769\nEpoch 644/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 26.4640 - val_accuracy: 0.0769\nEpoch 645/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 26.4301 - val_accuracy: 0.0769\nEpoch 646/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 26.4714 - val_accuracy: 0.0769\nEpoch 647/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 26.6509 - val_accuracy: 0.0769\nEpoch 648/1000\n11567/11567 [==============================] - 39s 3ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 26.2875 - val_accuracy: 0.0684\nEpoch 649/1000\n11567/11567 [==============================] - 38s 3ms/step - loss: 0.0022 - accuracy: 0.9979 - val_loss: 26.7018 - val_accuracy: 0.0769\nEpoch 650/1000\n11567/11567 [==============================] - 40s 3ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 26.5773 - val_accuracy: 0.0769\nEpoch 651/1000\n11567/11567 [==============================] - 53s 5ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 26.4014 - val_accuracy: 0.0769\nEpoch 652/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 26.7379 - val_accuracy: 0.0769\nEpoch 653/1000\n11567/11567 [==============================] - 42s 4ms/step - loss: 0.0022 - accuracy: 0.9984 - val_loss: 26.8728 - val_accuracy: 0.0769\nEpoch 654/1000\n11567/11567 [==============================] - 49s 4ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 26.9966 - val_accuracy: 0.0769\nEpoch 655/1000\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b519c1851098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(X_train, y_train, \n\u001b[0;32m----> 2\u001b[0;31m            batch_size=256, epochs=1000, validation_split=0.01)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {},
   "execution_count": 39
  },
  {
   "source": [
    "model.evaluate(X_test, y_test)[1]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "# We can summarize our model\n",
    "model.summary()"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "from keras import models\n",
    "model.save('model_10000_epoch.h5') "
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"model_10000_epoch.h5\")"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "import cv2\n",
    "filepath = './test_image/1.jpg'\n",
    "image_size = 50\n",
    "LR = 1e-3\n",
    "# img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE) \n",
    "img = cv2.imread(filepath, 0) \n",
    "img = cv2.resize(img, (image_size, image_size))\n",
    "img = img.reshape(1,50,50,1)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "prediction = model.predict_classes(img)\n",
    "prediction"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "# Evaluate the model using the training data \n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('python37': conda)",
   "language": "python",
   "name": "python37364bitpython37condab2ddadb2e2604623b8e2610b04b3d46a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}